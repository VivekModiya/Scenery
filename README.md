# Prompt2Video - AI-Powered Educational Video Generator

Transform any concept into a 15-second animated educational video using AI and Manim.

## ğŸš€ Features

- **Simple Input**: Enter any concept you want explained
- **AI-Powered**: Uses LLM to generate explanations and Manim code
- **Automated Animation**: Creates educational videos using Manim
- **REST API**: Clean API for integration with frontend applications
- **Job Queue**: Async processing with Redis-backed job management
- **Docker Support**: Easy deployment with Docker Compose

## ğŸ—ï¸ Architecture

```
Frontend (React) â†’ API Gateway â†’ Go Backend â†’ LLM Service â†’ Manim Renderer
                                      â†“
                              Redis Job Queue â† Workers
                                      â†“
                              PostgreSQL Database
```

## ğŸ“ Project Structure

```
prompt2video/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.go              # Application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ server.go            # HTTP server setup
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.go            # Configuration management
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ database.go          # Database initialization
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â””â”€â”€ video_handler.go     # HTTP request handlers
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ middleware.go        # HTTP middleware
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ models.go            # Data models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ llm_service.go       # LLM integration
â”‚       â””â”€â”€ video_service.go     # Video rendering
â”œâ”€â”€ docker-compose.yml           # Docker services
â”œâ”€â”€ Dockerfile                   # API container
â”œâ”€â”€ Makefile                     # Build automation
â”œâ”€â”€ go.mod                       # Go dependencies
â””â”€â”€ .env.example                 # Environment template
```

## ğŸ› ï¸ Setup & Installation

### Prerequisites

- Go 1.21+
- Docker & Docker Compose
- PostgreSQL (if running locally)
- Redis (if running locally)
- OpenAI API Key or Gemini API Key

### Quick Start with Docker

1. **Clone and configure**:

   ```bash
   git clone <repository>
   cd prompt2video
   cp .env.example .env
   # Edit .env with your API keys
   ```

2. **Start services**:

   ```bash
   make docker-up
   ```

3. **Test the API**:
   ```bash
   curl -X POST http://localhost:8080/api/v1/videos/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Explain Pythagorean theorem", "subject": "mathematics"}'
   ```

### Local Development

1. **Install dependencies**:

   ```bash
   make deps
   make install-tools
   ```

2. **Start database services**:

   ```bash
   docker-compose up postgres redis -d
   ```

3. **Run the API**:
   ```bash
   make run
   # Or for hot reload:
   make dev
   ```

## ğŸ“¡ API Endpoints

### Generate Video

```http
POST /api/v1/videos/generate
Content-Type: application/json

{
  "prompt": "Explain photosynthesis",
  "subject": "biology"
}
```

**Response:**

```json
{
  "id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "queued",
  "created_at": "2025-01-01T12:00:00Z"
}
```

### Check Job Status

```http
GET /api/v1/videos/status/{jobId}
```

**Response:**

```json
{
  "id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "completed",
  "video_url": "/storage/video_123_1609459200.mp4",
  "progress": 100,
  "created_at": "2025-01-01T12:00:00Z",
  "completed_at": "2025-01-01T12:00:15Z"
}
```


### List Generated Videos

```http
GET /api/v1/videos?page=1&limit=10
```


## ğŸ”§ Configuration

Environment variables (see `.env.example`):

| Variable         | Description                  | Default            |
| ---------------- | ---------------------------- | ------------------ |
| `PORT`           | API server port              | `8080`             |
| `DATABASE_URL`   | PostgreSQL connection string |                    |
| `REDIS_URL`      | Redis connection string      |                    |
| `OPENAI_API_KEY` | OpenAI API key               |                    |
| `GEMINI_API_KEY` | Google Gemini API key        |                    |
| `VIDEO_STORAGE`  | Video storage directory      | `./storage/videos` |
| `WORKER_COUNT`   | Number of worker processes   | `3`                |

## ğŸ¬ Video Generation Process

1. **User submits prompt** â†’ API creates job record
2. **Job queued** â†’ Redis manages processing queue
3. **Worker picks job** â†’ Updates status to "processing"
4. **LLM generates content** â†’ Creates explanation + Manim code
5. **Manim renders video** â†’ Produces MP4 file
6. **Job completed** â†’ Video available for download

## ğŸ³ Docker Setup

The application includes a complete Docker setup:

- **PostgreSQL**: Database for job and video metadata
- **Redis**: Job queue and caching
- **API Server**: Go backend service
- **Manim Container**: For video rendering (optional)

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Run with coverage
go test -cover ./...

# Benchmark tests
go test -bench=. ./...
```

## ğŸ“ˆ Monitoring & Logging

- Health check endpoint: `GET /health`
- Structured logging with request IDs
- Metrics for job processing times
- Rate limiting per IP address

## ğŸš€ Deployment

### Production Deployment

1. **Build for production**:

   ```bash
   make build-linux
   ```

2. **Deploy with Docker**:

   ```bash
   docker-compose -f docker-compose.prod.yml up -d
   ```

3. **Scale workers**:
   ```bash
   docker-compose up --scale api=3
   ```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:

- Create an issue on GitHub
- Check the documentation in `/docs`
- Review the API examples in `/examples`

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Manim](https://img.shields.io/badge/Powered%20by-Manim-orange.svg)](https://github.com/3b1b/manim)

## âœ¨ What is Scenery?

Scenery is an AI-powered video generation platform that converts natural language descriptions into professional-quality educational animations. Unlike traditional AI video generators that create static content, Scenery produces **programmatic videos** using the powerful [Manim](https://github.com/3b1b/manim) library, making every element editable and customizable.

### ğŸ¯ Key Features

- **ğŸ—£ï¸ Conversational Interface** - Chat with AI like you would with a colleague
- **ğŸ¨ Programmatic Generation** - Every animation is code-based and fully editable
- **ğŸ“š Educational Focus** - Built specifically for teaching and training content
- **ğŸ”§ Scene-by-Scene Editing** - Modify individual scenes without starting over
- **âš¡ Professional Quality** - Powered by advanced mathematical visualization tools
- **ğŸª No Technical Skills Required** - Natural language to professional animation

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Node.js 16+ (for frontend)
- FFmpeg (for video processing)

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/scenery.git
   cd scenery
   ```

2. **Install Python dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Install Manim**

   ```bash
   pip install manim
   ```

4. **Install frontend dependencies**

   ```bash
   cd frontend
   npm install
   cd ..
   ```

5. **Set up environment variables**

   ```bash
   cp .env.example .env
   # Add your OpenAI API key and other configurations
   ```

6. **Run the application**

   ```bash
   # Start the backend
   python app.py

   # Start the frontend (in another terminal)
   cd frontend && npm start
   ```

Visit `http://localhost:3000` to start creating!

## ğŸ’¬ How It Works

1. **Describe Your Concept**: Tell Scenery what you want to teach

   ```
   "Explain the Pythagorean theorem with a visual proof showing
   how the squares relate to each other"
   ```

2. **AI Generates Script**: Scenery creates Manim code for your concept
3. **Review & Edit**: Modify scenes, timing, colors, and content

4. **Generate Video**: Watch your idea come to life as a professional animation

## ğŸ¥ Example Prompts

- _"Create a video showing how photosynthesis works with animated molecules"_
- _"Explain sorting algorithms with visual comparisons of bubble sort vs quicksort"_
- _"Show the water cycle with animated weather patterns and transformations"_
- _"Demonstrate calculus derivatives using geometric interpretations"_

## ğŸ—ï¸ Project Structure

```
scenery/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Main FastAPI application
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ llm_client.py   # LLM integration
â”‚   â”‚   â””â”€â”€ prompt_engine.py # Prompt templates
â”‚   â”œâ”€â”€ video/
â”‚   â”‚   â”œâ”€â”€ manim_generator.py # Manim code generation
â”‚   â”‚   â””â”€â”€ renderer.py     # Video rendering pipeline
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes.py       # API endpoints
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ pages/          # Main pages
â”‚   â”‚   â””â”€â”€ services/       # API services
â”œâ”€â”€ templates/              # Manim code templates
â”œâ”€â”€ examples/               # Example projects
â””â”€â”€ docs/                   # Documentation
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# AI Configuration
OPENAI_API_KEY=your_openai_api_key
MODEL_NAME=gpt-4

# Video Configuration
RENDER_QUALITY=high
OUTPUT_FORMAT=mp4
MAX_DURATION=300

# Database
DATABASE_URL=postgresql://user:password@localhost/scenery
```

### Manim Settings

Scenery automatically configures Manim for optimal educational video rendering:

- **Resolution**: 1080p (configurable)
- **Frame Rate**: 30fps
- **Quality**: High
- **Background**: Customizable themes

## ğŸ¨ Customization

### Adding Custom Templates

Create new Manim templates in the `templates/` directory:

```python
# templates/physics_template.py
from manim import *

class PhysicsScene(Scene):
    def construct(self):
        # Your custom physics animation template
        pass
```

### Custom Themes

Define visual themes in `config/themes.json`:

```json
{
  "academic": {
    "background_color": "#f8f9fa",
    "primary_color": "#2c3e50",
    "accent_color": "#3498db"
  }
}
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Documentation

- [User Guide](docs/user-guide.md) - Complete usage instructions
- [API Reference](docs/api-reference.md) - Backend API documentation
- [Developer Guide](docs/developer-guide.md) - Contributing and development setup
- [Manim Integration](docs/manim-integration.md) - How Scenery works with Manim

## ğŸ—ºï¸ Roadmap

- [ ] **v1.0**: Core chat interface and basic Manim generation
- [ ] **v1.1**: Advanced scene editing and timeline control
- [ ] **v1.2**: Custom template marketplace
- [ ] **v1.3**: Collaborative editing features
- [ ] **v1.4**: Voice-to-animation generation
- [ ] **v2.0**: 3D animation support

## ğŸ› Known Issues

- Large animations may take significant time to render
- Complex mathematical expressions need careful prompt engineering
- Video preview requires full render (working on real-time preview)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [3Blue1Brown](https://github.com/3b1b/manim) for the incredible Manim library
- [OpenAI](https://openai.com) for GPT models that power our natural language understanding
- The educational content creator community for inspiration and feedback

## ğŸ“ Support

- ğŸ“§ Email: support@scenery.ai
- ğŸ’¬ Discord: [Join our community](https://discord.gg/scenery)
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/scenery/issues)
- ğŸ“š Docs: [Documentation Site](https://docs.scenery.ai)

---

**Made with â¤ï¸ for educators who want to bring their ideas to life**

_Transform your teaching. Engage your audience. Make learning stick._
